# 需要完成的工作

~~现在需要做一个demo，完成借助大模型的harness自动生成。~~

~~给的例子是一个用git进行版本管理的开源组件，其中提供了一个sh文件用于抽取源文件中的代码改动。最后会得到一个txt文件，其中包含了发生改动的源文件名字，以及对应的改动位置（代码行号）~~

~~我需要结合这个信息，先进行一些代码静态分析，找到能到达目标位置的一个函数调用链，然后通过这个函数调用链的信息给大模型来完成harness的生成~~

# 现在的问题

这个代码静态分析怎么做？

我只能得到代码被改动位置的信息，也就是一个文件名和对应的改动位置。

我要找到一条能够到达这个改动位置的调用链，这个调用链怎么找？

函数的调用链构成是一个静态的分析，我应该先构建一个调用图，通过调用图中的调用关系来找到一条链路。

但是在被改动文件中即使假如可以找到一条由A->B->target的链条，但是这个链条的起始点A可能并不是真正的入口，还需要结合项目中的其他文件来不断扩展这个调用链直到找到真正的入口点。

只要能找到这个完整的调用链条一切就都好说

**GLLVM**，据老大哥所说可以抽取整个项目的调用图

现在完成了调用链的抽取，但是好像只有调用链没有什么作用。

~~cflow是一个面对C的静态分析工具，用来做CG抽取之类的工作~~

~~cflow在完成编译后是一个命令行工具，触发它源码中各种调用逻辑的本质上来说是应该是给cflow用于分析的源文件~~

~~所以可以让LLM产生一些应用于cflow分析的.c文件用作种子~~

**现在有一个问题是当我获得了一个可用的harness时，应该如何利用这个harness，或者说是在这个harness中进行变异？**

如果我使用LLM来生成harness，那么我就依赖于LLM对于目标对象（库、具体程序的了解）

对于一般的程序是不好生成harness的，所以我的目标就应该针对库。

**考虑一种场景，如果我们测试的库是一个非公开的库，所以大模型不具备相关的知识，这个情况下来生成harness的话，直接生成显然是不行的**

直接让LLM生成harness显然是不行的，它没有这方面的知识，但是LLM仍然具有推理合成的能力，提供某些逻辑上的分类指导

能否做一个全路径的fuzzer？

# 整体架构构思

两个大的部分：harness的生成以及实际的定向fuzz

一个辅助部分为静态分析

## harness生成

*进行harness的优化？*

能否通过定向fuzz的某些信息来反馈给harness生成来优化生成的harness的效果

根据一篇论文中的想法，将库中的API按照其命令规则上的功能特性划分为一些待选组，在实际的harness生成当中，提供给LLM的就可以是一些待选择的API，以此来

harness的优化所需要的一些信息？

harness最终会被用于定向fuzz，根据师兄的论文中的对于无关代码的论述，可不可以在一次dry run过后剪除掉触发了过多无关代码（或者说没有包含足够有关代码）的harness。**另外收集到的静态分析的相关信息可否用于harness的优化？**

~~考虑额外提供一些对于库的描述：开发者文档，操作手册，补丁/漏洞详情等。以此来增强生成的能力。~~

~~将分类的API与从静态分析中获取到的信息形成一个name:tag的对应关系，以此来提升LLM对一些比较关键API的注意程度~~

我通过CG抽取的就是一条从库中某个API开始的调用链，这个调用链一定包含对应的目标函数，对于LLM已经学习过的开源项目来说，这样就够了。

会获得相当多数量的调用链（几十条），对于每条调用链都生成一次harness，通过一次dry run过滤掉距离表现上不好的，保留一些高质量的harness

**代表harness质量的标准应该如何设计？**

**如何解决可能由harness自身构造失败造成的假阳性问题？**





## 定向fuzz

从pathfuzz中获得的一个想法：依赖传统的随机变异运用于定向fuzz中的效果不太好，这一点可以改进

我需要有一套高效的，可以实现的距离指标及种子得分计算模式来作为fuzz seed选择的引导

对于AFLGO之中会对所有基本块和函数进行距离计算的问题，可以考虑某些方法剔除掉这些与触发无关的距离计算（这好像就是selectfuzz的工作？）

对于某些论文中提到的偏移基本块的处理问题，可以做一些处理。



# 当前进行的工作

## 抽取调用图CG

cflow本身就是一个静态的代码分析工具，可以就用它来尝试抽取一下项目中的调用关系CG，效果上看起来比较正确

之后尝试使用了老大哥推荐的GLLVM生成CG，得到了一个应该是比较完整的调用图。同时记录一下使用GLLVM抽取CG的 操作过程：

首先使用GLLVM封装的gclang对项目进行编译

```
CC=gclang ./configure
make
```

完成make生成了对应项目下的一个可执行文件或是一个库，这个可执行文件或是库是经过GLLVM处理的，然后用GLLVM封装的一个抽取bc文件的程序抽取一下对应的bc文件

```
get-bc -o <name of bitcode file> <path to executable>
```

之后就可以得到一个bc文件，用opt对这个bc文件进行分析即可，比如这里要抽取一个CG

```
opt -passes='dot-callgraph' cflow_gllvm_bitcode.bc -disable-output
```

## 分析CG

对CG进行分析得到后续可能用于harness生成的调用信息，现在想的是抽取一条完整的调用链出来给LLM来完成harness的生成

现在已经完成了调用链的抽取，作为提示词中的信息之一传递给LLM

## LLM类

设计了一个LLM类来完成需要使用大模型的各种操作



先尝试提供cflow的操作手册以及前面提取到的调用链给LLM尝试生成fuzz driver，使用的提示词：

```
can you generate a fuzzing driver for a GNU tools whose name is cflow taht could trriger a function named "inverted_tree".here is a pdf that tell you how use cflow,and here also is a call chain that include the target function:

['main', 'output', 'inverted_tree', 'xrealloc', 'realloc']

This list contains functions arranged in the order they are called.
```

LLM回复了Libfuzzer的fuzzdriver，但是只是简单的用到了Libfuzzer生成的随机数据。对于cflow这种需高度结构化的工具没有什么太大的实际意义

**与范博沟通发现对于这个cflow生成harness确实没有什么意义，后面换一个开源的C库来进行测试，这里选择的是libxml2这个库**



fork了GitHub的开源库，尝试使用GLLVM对其进行编译并提取调用图

在编译libxml2时遇到了autoconfig找不到python的问题，使用命令：

```
CC=/home/youngmith/gllvm/bin/gclang ./autogen.sh --without-python --prefix=/usr/local
```

忽略掉对python的检查，不影响后续的编译

只完成make而不完成install的话编译生成的.o文件和.so文件在工程目录的.libs文件夹下，顺便记一下有几个不太常见的文件：

**`.lo` 文件 (Libtool Object File)**

- **来源:** `.lo` 文件是在使用 **GNU Libtool** 构建共享库时生成的。
- 内容:
  - `.lo` 文件本质上也是包含了源代码编译后的机器码，但它通常会包含一些 **额外的元数据 (Metadata)**，这些元数据是 `libtool` 用来处理不同平台下共享库的差异的。
  - 这些元数据可能包括关于如何生成位置无关代码 (PIC, Position Independent Code) 的信息，以及构建共享库所需的其他特定于平台的细节。
  - 在某些情况下，`.lo` 文件可能只是简单地包装了对应的 `.o` 文件。
- **作用:** `.lo` 文件是 `libtool` 为了实现 **跨平台共享库构建** 而引入的一种中间格式。`libtool` 使用 `.lo` 文件来生成最终的共享库文件（例如 `.so`、`.dylib`、`.dll`）。
- 特点:
  - 与 `.o` 文件类似，每个源代码文件在通过 `libtool` 编译时可能会生成一个 `.lo` 文件。
  - `.lo` 文件也是 **平台相关的**，但它们包含了 `libtool` 在不同平台生成兼容共享库所需的信息。

**`.la` 文件 (Libtool Archive File)**

- **来源:** `.la` 文件也是在使用 **GNU Libtool** 构建库时生成的。
- 内容:
  - `.la` 文件 **不是实际的库文件**，而是一个 **文本文件 (ASCII Text File)**。
  - 它包含了关于如何链接到实际库的信息，包括：
    - 实际共享库文件的路径和名称（例如 `.so` 或 `.dylib` 文件）。
    - 库的依赖关系（它依赖于哪些其他的库）。
    - 在链接时需要使用的特殊标志。
    - 可能包含一个用于静态链接的 `.a` 库的路径。
- **作用:** `.la` 文件是 `libtool` 用来管理库的 **链接** 过程的。当其他程序或库需要链接到这个由 `libtool` 构建的库时，链接器会首先读取 `.la` 文件中的信息，然后根据这些信息去找到并链接实际的共享库文件。这使得链接过程更加平台无关。
- 特点:
  - 每个通过 `libtool` 构建的库通常会有一个对应的 `.la` 文件。
  - `.la` 文件本身是 **文本文件**，可以查看其内容。
  - 在一些现代构建系统中，`.la` 文件有时会被认为是不必要的复杂性，并且在某些情况下可能会导致问题。因此，一些项目可能会选择不生成 `.la` 文件。



尝试提取这个库的调用关系图，使用gllvm：

```sh
./get-bc -o /home/youngmith/autoharness_demo/auto_harness/libxml2.so.bc /home/youngmith/autoharness_demo/libxml2_for_test/.libs/libxml2.so.16.1.0
```

生成CG的.dot文件：

```sh
opt -passes='dot-callgraph' libxml2.so.bc -disable-output
```

提取出来的.dot文件大概在一万行左右，比较庞大

**这里发现一个问题，使用之前编写的抽取调用链的程序对这个一万行左右的.dot文件进行分析时需要很长的时间，后面看下怎么解决这个问题**

**~~tips：这个问题是由于我之前在遍历root的情况下又套了一层遍历leaves，这个遍历叶子节点的操作没有意义，只用遍历root节点就行~~**

**这里由于目标库中的调用关系非常复杂且数量庞大，所以从根节点进行遍历所花费的时间非常的多，所以这里采用一个逆向深搜，从目标节点开始向上寻找根节点，缩短时间的同时限制搜寻到的数量（比如只收集十条包含目标节点的路径，防止路径数量爆炸导致的时间大量耗费）**

收集libxml2的相关的操作手册之类的东西，这里找到一个相关的网站：

```url
http://xmlsoft.org/html/
```

现在开始编写prompt，提供一下信息：

1. API调用链
2. 收集到的关于libxml2的操作手册网页
3. 目标函数所处的源文件名（暂做考虑）

tips：使用LLM的API接口无法给模型传入网页让LLM进行分析，考虑模仿范博的方法，通过python中的PDF将PDF转换成文本提供给LLM以作参考

构建prompt如下：

```python
 code_prompt="""
        you are an expert in fuzzing, please write a fuzz harness that could trigger the target function named "%s" in an open source library called "libxml2". \
        Here is some data about the libxm2 library to help you complete the harness generation: \
        1. this page is the reference of the libxml2 library: http://xmlsoft.org/html/ \
        2. this is a call chain that include the target function: %s \
        3. this target function is located in the %s in libxml2 source code. \
        these information may be helpful when you generate the fuzz harness. \
        The harness you gernerate should include the libxml2 library and complie successfully. \
        
        Format requirements : The code should follow the C or C++ code specification, and the program code should be complete and properly formatted.
        In the code, you should write a long sentence without using line breaks, avoiding the newline character \ n.
        Try not to use 'printf' in generated code. Don’t make up APIs that don't exist.

        Here is a template function that you can refer to its format, but you don't have to follow it strictly. \
        
        #include <stdio.h>
        #include <stdlib.h>
        #include <libxml/parser.h>
        #include <libxml/tree.h>

        /* Encoding Conversion Layer (Platform-dependent implementation) */
        xmlChar* encode_to_utf8(const char* input) {
            // Windows example: Use iconv for GBK->UTF-8 conversion
            // Linux example: Utilize built-in encoding conversion APIs
            return BAD_CAST input; // Replace with actual conversion logic
        }

        int main() {
            /* Initialization System */
            xmlInitParser();
            LIBXML_TEST_VERSION
            
            /* Document Container Declaration */
            xmlDocPtr doc = NULL;
            xmlNodePtr root_node = NULL;

            /* Main Operations Section */
            // Branch 1: Create new document
            doc = xmlNewDoc(BAD_CAST "1.0");
            root_node = xmlNewNode(NULL, encode_to_utf8("root_node"));
            xmlDocSetRootElement(doc, root_node);

            // Branch 2: Parse existing document
            // doc = xmlReadFile("input.xml", NULL, XML_PARSE_NOBLANKS)
            
            /* Node Operation Template */
            if(root_node) {
                // Text node construction
                xmlNewTextChild(root_node, NULL, 
                            encode_to_utf8("child_node"), 
                            encode_to_utf8("node_content"));
                
                // Attribute operation template
                xmlNewProp(root_node, 
                        encode_to_utf8("attribute_name"), 
                        encode_to_utf8("attribute_value"));
            }

            /* Persistence Module */
            if(doc) {
                xmlSaveFormatFileEnc("output.xml", doc, "UTF-8", 1); // Universal encoding storage
                // Chinese environment option: xmlSaveFormatFileEnc("cn.xml", doc, "GB2312", 1)
            }

            /* Error Handling Stub */
            if(!doc) {
                fprintf(stderr, "Document initialization failed");
                goto cleanup;
            }

        cleanup:
            /* Resource Cleanup Stack */
            if(doc) xmlFreeDoc(doc);
            xmlCleanupParser();
            return EXIT_SUCCESS;
        }

        when you finish the code generation, please give me the compile command, the compile command shoulde be given in the following form:\n
        compile command: "the compile command"
        """
```

后面模仿范博的项目使用json_schema 限定LLM的回复格式为json，且包含的properties只有我需要的code 和 compile_command，另外设置模型temperature等属性限制回答的生成风格。

现在完成了harness代码和其对应编译命令的生成

### harness_fix：

这个函数尝试通过报错信息修复之前通过LLM生成的harness

**这里模仿范博的项目，限制每个harness的修复次数为3次。那么对应的我就需要生成一批harness（现在暂时定为3个）**

## harness类

模仿范博的方式让大模型给出的编译命令中用a.c a.out代替源文件和生成的可执行文件，后面通过正则匹配来完成对编译命令的修改。

之后准备考虑在完成编译后检验是否出现编译错误，收集编译错误反馈给大模型尝试修复编译错误，直到获得一个可以通过编译的harness为止

设计了一个harness类用于处理与harness有关的操作

### compile_test

这个函数用于测试编译是否通过。这里有个问题，如果我需要编译测试的harness是之前已经生成的harness在完成harness_fix之后产生修改的harness，那么compile_test函数中就不能重复的进行保存harness和修正编译命令的操作。

**对于上面这个问题，将保存代码和修正编译命令这个操作移动到LLM类中的harness生成和修复函数中**

## 生成harness

这里完成自动化的对于测试harness的生成。

生成harness所需要的一些参数是：target_func, call_chain, target_location(目标函数所在的源文件位置) 

对于这三个参数分别设计三个函数来获取：extract_call_chains、get_target_func_location、get_target_function

### extract_call_chains

即调用前面构造的调用链提取函数，返回十条（或者小于十条）以目标函数作为终点的调用链

### get_target_func_location

编写了一个脚本（速度远大于用python程序实现），这个脚本会找到目标的工程目录下所有包含了这个目标函数的文件。

在主要逻辑开始执行前将对应脚本复制到项目目录的对应位置下



### get_target_function

这里我们是假设这个项目使用的git管理，之前给的那个参考项目cflow中的有个脚本是通过git的diff来抽取某两个commit之间被修改了的所有函数名。

我可以利用这个脚本抽取所有被修改过后的函数名形成一个列表，对这个列表中的的每一个函数都进行一次harness的生成

### gen_harness

当前的设计思路初步构想的是设计一个循环，这个循环的结束条件暂时设定为能够寻找一个能够通过编译正常运行的harness

## main函数

这个main函数主要用于处理命令行传入的参数以及调度前面已经封装好的函数。

这里主要考虑命令行参数逻辑的处理，会涉及一些互斥参数之类的处理，首先要理一下几种我需要的工作方式：

1. 首先是只针对工程项目中的某个函数进行harness生成
2. 然后是针对整个工程项目（版本管理建立在git上）的某两个commit节点间出现修改所有函数进行harness的生成

对于第1点，命令行需要传入的参数是目标函数的名称，目标工程项目的所在所在路径

对于第2点，命令行需要传入的参数是两个commit编号，以及目标工程项目所在的路劲

所以在功能实现上，传入目标函数名称和传入commit编号在命令行参数的角度上二者是互斥的。

对于整个工程项目被修改函数的harness生成这一功能，从get_target_function处获得的函数名应该是一个列表





