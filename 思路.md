# 需要完成的工作

现在需要做一个demo，完成借助大模型的harness自动生成。

给的例子是一个用git进行版本管理的开源组件，其中提供了一个sh文件用于抽取源文件中的代码改动。最后会得到一个txt文件，其中包含了发生改动的源文件名字，以及对应的改动位置（代码行号）

我需要结合这个信息，先进行一些代码静态分析，找到能到达目标位置的一个函数调用链，然后通过这个函数调用链的信息给大模型来完成harness的生成

# 现在的问题

这个代码静态分析怎么做？

我只能得到代码被改动位置的信息，也就是一个文件名和对应的改动位置。

我要找到一条能够到达这个改动位置的调用链，这个调用链怎么找？

函数的调用链构成是一个静态的分析，我应该先构建一个调用图，通过调用图中的调用关系来找到一条链路。

但是在被改动文件中即使假如可以找到一条由A->B->target的链条，但是这个链条的起始点A可能并不是真正的入口，还需要结合项目中的其他文件来不断扩展这个调用链直到找到真正的入口点。

只要能找到这个完整的调用链条一切就都好说

**GLLVM**，据老大哥所说可以抽取整个项目的调用图

现在完成了调用链的抽取，但是好像只有调用链没有什么作用。

~~cflow是一个面对C的静态分析工具，用来做CG抽取之类的工作~~

~~cflow在完成编译后是一个命令行工具，触发它源码中各种调用逻辑的本质上来说是应该是给cflow用于分析的源文件~~

~~所以可以让LLM产生一些应用于cflow分析的.c文件用作种子~~

**现在有一个问题是当我获得了一个可用的harness时，应该如何利用这个harness，或者说是在这个harness中进行变异？**

# 整体架构构思

两个大的部分：harness的生成以及实际的定向fuzz

## harness生成

*进行harness的优化？*

harness的优化所需要的一些信息

## 定向fuzz

能否通过定向fuzz的某些信息来反馈给harness生成来优化生成的harness的效果

# cuda-example

## 调用图与顺序图

项目中使用NVIDIA提供的操作手册和一些实例程序抽取了调用图（call graph）和顺序图（order graph）。是完全依赖大模型结合提示词工程进行抽取，格式存储为一个json文件。从操作手册中抽取了call graph，从示例程序中抽取了order graph。其通过大模型抽取的api调用链在json文件中的呈现为：

call graph：

```
[{"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaSetDevice", "tail_type": "CUDA_API"}, 
{"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaStreamCreateWithFlags", "tail_type": "CUDA_API"}, 
{"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaMallocAsync", "tail_type": "CUDA_API"}, 
{"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"},
 {"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaFreeAsync", "tail_type": "CUDA_API"}, 
{"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaStreamSynchronize", "tail_type": "CUDA_API"}, 
{"head": "vectorAddGPU", "head_type": "__global__", "description": "Adds two vectors on the GPU.", "relation": "calls", "tail": "cudaMemcpyAsync", "tail_type": "CUDA_API"}, 
{"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaDeviceGetDefaultMemPool", "tail_type": "CUDA_API"}, 
{"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaMemPoolSetAttribute", "tail_type": "CUDA_API"}, 
{"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaEventRecord", "tail_type": "CUDA_API"}, 
{"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaEventSynchronize", "tail_type": "CUDA_API"}, 
{"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaEventElapsedTime", "tail_type": "CUDA_API"}, 
{"head": "checkCudaErrors", "head_type": "__host__", "description": "Checks for CUDA errors.", "relation": "calls", "tail": "cudaEventCreate", "tail_type": "CUDA_API"}]}
```

这些head description relation tail之类的是用提示词工程抽出来的对于调用关系的描述

order graph：

```
 {"order": [["cudaOccupancyMaxPotentialClusterSize", "cudaOccupancyMaxPotentialClusterSize"], ["__cluster_dims__", "cudaLaunchKernelEx"], ["cudaLaunchKernelEx", "cudaLaunchAttributeClusterDimension"], ["num_threads", "num_blocks"], ["dim_threads", "dim_blocks"]]}}
```

这里的order graph是调用顺序关系，是通过示例程序抽取了其中各个api 之间的调用关系

## 构建关系图谱

前面抽出来的调用图和顺序图被用于后面构建这个关系图谱

通过检索cuda中的.a文件确定所有的api签名，存储为一个包含所有唯一api的集合，用于过滤前面LLM抽取来的api序列

然后就是建图，这里使用了一个python库：**networkX**，这个可以用于构建各种各样的网络

总的来说就是结合前面的提取出来的json文件中的信息来生成一个关系图谱，因为json里面存储的信息都是api的链式关系，所以不需要进行过多的处理就能直接搓出来一张关系图（有向图），图的边被分为两类：call和order，根据其是在什么json里面被构建的

随机取出图中的一个节点，判断该节点是否入度大于1，如果是的话，通过广度优先搜索找到以其为源节点的五条路径

## 维护bitmap

统计了前面构建的关系图谱中call边和order边数量，进行了一定处理，删除了图中的一些明显错误的节点和边（比如自己调用自己的边就会被删掉）

然后为每一个API生成一个独特的ID，对于两个节点中间的边结合两个节点在前面被分配的独特ID构造了这个边的独特ID

到这里完成对于前面通过示例程序和操作手册提取的调用关系和顺序关系在bitmap里面的映射

然后后面如果通过fuzz触发了新的API则会把这个API设置ID后添加进bitmap之中

## 生成harness

首先初始化关系图谱，并通过初始关系图谱初始化bitmap。

首先抽出原始关系图谱中的5条路径（路径采样），对于采样到的5条路径（这里的节点为随机选择，可能并不是一个传统意义上的源节点）中的每一条，抽取出这条路径中的调用关系如下：

```
        Return's format is:
          1:  [ api1 calls api2, ..., apin calls apin+1 ]
          2:  [ (api1, api2), ..., (apin, apin+1) ]
```

在这里对于采样到的每一条路径遍历其中的节点间的路径并结合初始api order bitmap看是否找到了新的order（同理也判断了下是不是找到了新的call）

最后会记录两个bitmap，分别是bitmap_api_order_edge_trace和bitmap_api_call_edge_trace

之后就进入了harness的生成过程，首先是使用路径抽样出来的5条路径来生成harness，这里的提示词限制了大模型必须按给出的API顺序构建harness

 提示词要求大模型给出了生成的harness以及这个harness对应的编译命令

然后根据大模型给出的编译命令进行尝试编译，进行若干轮bugfix，主要原理是通过报错信息来修复一些可以人力修复的bug，比如去除一些可能是有LLM编造的API名字。

然后将根据前面的报错API结合一段prompt发给LLM让其尝试修复后得到修复代码

之后又对这个生成的harness进行了一次重构和再一次的测试编译 （即为代码中的_sep，但是暂时没搞懂这一步的含义是什么？->这一步是为了分离出原始harness中可以被抽取出来做变异的harness，利用大模型抽取可以被独立变异的变量）

后续的wrap环节是将前面sep环节生成的变量抽取版的harness中的独立变量抽取出来形成一个列表（也就是独立变量分离出来方便后续变异）后续对sep这一步中被标记为初始化变量的部分用一个while循环将其包起来，在这个while循环中对提取到的变量（包括变量和malloc这类内存分配操作）进行模仿AFL中havoc逻辑的变异

之后按照一个逻辑采样harness列表中的5个harness进行并行的模糊测试

# 当前进行的工作

## 抽取调用图CG

cflow本身就是一个静态的代码分析工具，可以就用它来尝试抽取一下项目中的调用关系CG，效果上看起来比较正确

之后尝试使用了老大哥推荐的GLLVM生成CG，得到了一个应该是比较完整的调用图。同时记录一下使用GLLVM抽取CG的 操作过程：

首先使用GLLVM封装的gclang对项目进行编译

```
CC=gclang ./configure
make
```

完成make生成了对应项目下的一个可执行文件或是一个库，这个可执行文件或是库是经过GLLVM处理的，然后用GLLVM封装的一个抽取bc文件的程序抽取一下对应的bc文件

```
get-bc -o <name of bitcode file> <path to executable>
```

之后就可以得到一个bc文件，用opt对这个bc文件进行分析即可，比如这里要抽取一个CG

```
opt -passes='dot-callgraph' cflow_gllvm_bitcode.bc -disable-output
```

## 分析CG

对CG进行分析得到后续可能用于harness生成的调用信息，现在想的是抽取一条完整的调用链出来给LLM来完成harness的生成

现在已经完成了调用链的抽取，作为提示词中的信息之一传递给LLM

## LLM类

设计了一个LLM类来完成需要使用大模型的各种操作



先尝试提供cflow的操作手册以及前面提取到的调用链给LLM尝试生成fuzz driver，使用的提示词：

```
can you generate a fuzzing driver for a GNU tools whose name is cflow taht could trriger a function named "inverted_tree".here is a pdf that tell you how use cflow,and here also is a call chain that include the target function:

['main', 'output', 'inverted_tree', 'xrealloc', 'realloc']

This list contains functions arranged in the order they are called.
```

LLM回复了Libfuzzer的fuzzdriver，但是只是简单的用到了Libfuzzer生成的随机数据。对于cflow这种需高度结构化的工具没有什么太大的实际意义

**与范博沟通发现对于这个cflow生成harness确实没有什么意义，后面换一个开源的C库来进行测试，这里选择的是libxml2这个库**



fork了GitHub的开源库，尝试使用GLLVM对其进行编译并提取调用图

在编译libxml2时遇到了autoconfig找不到python的问题，使用命令：

```
CC=/home/youngmith/gllvm/bin/gclang ./autogen.sh --without-python --prefix=/usr/local
```

忽略掉对python的检查，不影响后续的编译

只完成make而不完成install的话编译生成的.o文件和.so文件在工程目录的.libs文件夹下，顺便记一下有几个不太常见的文件：

**`.lo` 文件 (Libtool Object File)**

- **来源:** `.lo` 文件是在使用 **GNU Libtool** 构建共享库时生成的。
- 内容:
  - `.lo` 文件本质上也是包含了源代码编译后的机器码，但它通常会包含一些 **额外的元数据 (Metadata)**，这些元数据是 `libtool` 用来处理不同平台下共享库的差异的。
  - 这些元数据可能包括关于如何生成位置无关代码 (PIC, Position Independent Code) 的信息，以及构建共享库所需的其他特定于平台的细节。
  - 在某些情况下，`.lo` 文件可能只是简单地包装了对应的 `.o` 文件。
- **作用:** `.lo` 文件是 `libtool` 为了实现 **跨平台共享库构建** 而引入的一种中间格式。`libtool` 使用 `.lo` 文件来生成最终的共享库文件（例如 `.so`、`.dylib`、`.dll`）。
- 特点:
  - 与 `.o` 文件类似，每个源代码文件在通过 `libtool` 编译时可能会生成一个 `.lo` 文件。
  - `.lo` 文件也是 **平台相关的**，但它们包含了 `libtool` 在不同平台生成兼容共享库所需的信息。

**`.la` 文件 (Libtool Archive File)**

- **来源:** `.la` 文件也是在使用 **GNU Libtool** 构建库时生成的。
- 内容:
  - `.la` 文件 **不是实际的库文件**，而是一个 **文本文件 (ASCII Text File)**。
  - 它包含了关于如何链接到实际库的信息，包括：
    - 实际共享库文件的路径和名称（例如 `.so` 或 `.dylib` 文件）。
    - 库的依赖关系（它依赖于哪些其他的库）。
    - 在链接时需要使用的特殊标志。
    - 可能包含一个用于静态链接的 `.a` 库的路径。
- **作用:** `.la` 文件是 `libtool` 用来管理库的 **链接** 过程的。当其他程序或库需要链接到这个由 `libtool` 构建的库时，链接器会首先读取 `.la` 文件中的信息，然后根据这些信息去找到并链接实际的共享库文件。这使得链接过程更加平台无关。
- 特点:
  - 每个通过 `libtool` 构建的库通常会有一个对应的 `.la` 文件。
  - `.la` 文件本身是 **文本文件**，可以查看其内容。
  - 在一些现代构建系统中，`.la` 文件有时会被认为是不必要的复杂性，并且在某些情况下可能会导致问题。因此，一些项目可能会选择不生成 `.la` 文件。



尝试提取这个库的调用关系图，使用gllvm：

```sh
./get-bc -o /home/youngmith/autoharness_demo/auto_harness/libxml2.so.bc /home/youngmith/autoharness_demo/libxml2_for_test/.libs/libxml2.so.16.1.0
```

生成CG的.dot文件：

```sh
opt -passes='dot-callgraph' libxml2.so.bc -disable-output
```

提取出来的.dot文件大概在一万行左右，比较庞大

**这里发现一个问题，使用之前编写的抽取调用链的程序对这个一万行左右的.dot文件进行分析时需要很长的时间，后面看下怎么解决这个问题**

**~~tips：这个问题是由于我之前在遍历root的情况下又套了一层遍历leaves，这个遍历叶子节点的操作没有意义，只用遍历root节点就行~~**

**这里由于目标库中的调用关系非常复杂且数量庞大，所以从根节点进行遍历所花费的时间非常的多，所以这里采用一个逆向深搜，从目标节点开始向上寻找根节点，缩短时间的同时限制搜寻到的数量（比如只收集十条包含目标节点的路径，防止路径数量爆炸导致的时间大量耗费）**

收集libxml2的相关的操作手册之类的东西，这里找到一个相关的网站：

```url
http://xmlsoft.org/html/
```

现在开始编写prompt，提供一下信息：

1. API调用链
2. 收集到的关于libxml2的操作手册网页
3. 目标函数所处的源文件名（暂做考虑）

tips：使用LLM的API接口无法给模型传入网页让LLM进行分析，考虑模仿范博的方法，通过python中的PDF将PDF转换成文本提供给LLM以作参考

构建prompt如下：

```python
 code_prompt="""
        you are an expert in fuzzing, please write a fuzz harness that could trigger the target function named "%s" in an open source library called "libxml2". \
        Here is some data about the libxm2 library to help you complete the harness generation: \
        1. this page is the reference of the libxml2 library: http://xmlsoft.org/html/ \
        2. this is a call chain that include the target function: %s \
        3. this target function is located in the %s in libxml2 source code. \
        these information may be helpful when you generate the fuzz harness. \
        The harness you gernerate should include the libxml2 library and complie successfully. \
        
        Format requirements : The code should follow the C or C++ code specification, and the program code should be complete and properly formatted.
        In the code, you should write a long sentence without using line breaks, avoiding the newline character \ n.
        Try not to use 'printf' in generated code. Don’t make up APIs that don't exist.

        Here is a template function that you can refer to its format, but you don't have to follow it strictly. \
        
        #include <stdio.h>
        #include <stdlib.h>
        #include <libxml/parser.h>
        #include <libxml/tree.h>

        /* Encoding Conversion Layer (Platform-dependent implementation) */
        xmlChar* encode_to_utf8(const char* input) {
            // Windows example: Use iconv for GBK->UTF-8 conversion
            // Linux example: Utilize built-in encoding conversion APIs
            return BAD_CAST input; // Replace with actual conversion logic
        }

        int main() {
            /* Initialization System */
            xmlInitParser();
            LIBXML_TEST_VERSION
            
            /* Document Container Declaration */
            xmlDocPtr doc = NULL;
            xmlNodePtr root_node = NULL;

            /* Main Operations Section */
            // Branch 1: Create new document
            doc = xmlNewDoc(BAD_CAST "1.0");
            root_node = xmlNewNode(NULL, encode_to_utf8("root_node"));
            xmlDocSetRootElement(doc, root_node);

            // Branch 2: Parse existing document
            // doc = xmlReadFile("input.xml", NULL, XML_PARSE_NOBLANKS)
            
            /* Node Operation Template */
            if(root_node) {
                // Text node construction
                xmlNewTextChild(root_node, NULL, 
                            encode_to_utf8("child_node"), 
                            encode_to_utf8("node_content"));
                
                // Attribute operation template
                xmlNewProp(root_node, 
                        encode_to_utf8("attribute_name"), 
                        encode_to_utf8("attribute_value"));
            }

            /* Persistence Module */
            if(doc) {
                xmlSaveFormatFileEnc("output.xml", doc, "UTF-8", 1); // Universal encoding storage
                // Chinese environment option: xmlSaveFormatFileEnc("cn.xml", doc, "GB2312", 1)
            }

            /* Error Handling Stub */
            if(!doc) {
                fprintf(stderr, "Document initialization failed");
                goto cleanup;
            }

        cleanup:
            /* Resource Cleanup Stack */
            if(doc) xmlFreeDoc(doc);
            xmlCleanupParser();
            return EXIT_SUCCESS;
        }

        when you finish the code generation, please give me the compile command, the compile command shoulde be given in the following form:\n
        compile command: "the compile command"
        """
```

后面模仿范博的项目使用json_schema 限定LLM的回复格式为json，且包含的properties只有我需要的code 和 compile_command，另外设置模型temperature等属性限制回答的生成风格。

现在完成了harness代码和其对应编译命令的生成

### harness_fix：

这个函数尝试通过报错信息修复之前通过LLM生成的harness

**这里模仿范博的项目，限制每个harness的修复次数为3次。那么对应的我就需要生成一批harness（现在暂时定为3个）**

## harness类

模仿范博的方式让大模型给出的编译命令中用a.c a.out代替源文件和生成的可执行文件，后面通过正则匹配来完成对编译命令的修改。

之后准备考虑在完成编译后检验是否出现编译错误，收集编译错误反馈给大模型尝试修复编译错误，直到获得一个可以通过编译的harness为止

设计了一个harness类用于处理与harness有关的操作

### compile_test

这个函数用于测试编译是否通过。这里有个问题，如果我需要编译测试的harness是之前已经生成的harness在完成harness_fix之后产生修改的harness，那么compile_test函数中就不能重复的进行保存harness和修正编译命令的操作。

**对于上面这个问题，将保存代码和修正编译命令这个操作移动到LLM类中的harness生成和修复函数中**

## 生成harness

这里完成自动化的对于测试harness的生成。

生成harness所需要的一些参数是：target_func, call_chain, target_location(目标函数所在的源文件位置) 

对于这三个参数分别设计三个函数来获取：extract_call_chains、get_target_func_location、get_target_function

### extract_call_chains

即调用前面构造的调用链提取函数，返回十条（或者小于十条）以目标函数作为终点的调用链

### get_target_func_location

编写了一个脚本（速度远大于用python程序实现），这个脚本会找到目标的工程目录下所有包含了这个目标函数的文件。

在主要逻辑开始执行前将对应脚本复制到项目目录的对应位置下



### get_target_function

这里我们是假设这个项目使用的git管理，之前给的那个参考项目cflow中的有个脚本是通过git的diff来抽取某两个commit之间被修改了的所有函数名。

我可以利用这个脚本抽取所有被修改过后的函数名形成一个列表，对这个列表中的的每一个函数都进行一次harness的生成

### gen_harness

当前的设计思路初步构想的是设计一个循环，这个循环的结束条件暂时设定为能够寻找一个能够通过编译正常运行的harness

## main函数

这个main函数主要用于处理命令行传入的参数以及调度前面已经封装好的函数。

这里主要考虑命令行参数逻辑的处理，会涉及一些互斥参数之类的处理，首先要理一下几种我需要的工作方式：

1. 首先是只针对工程项目中的某个函数进行harness生成
2. 然后是针对整个工程项目（版本管理建立在git上）的某两个commit节点间出现修改所有函数进行harness的生成

对于第1点，命令行需要传入的参数是目标函数的名称，目标工程项目的所在所在路径

对于第2点，命令行需要传入的参数是两个commit编号，以及目标工程项目所在的路劲

所以在功能实现上，传入目标函数名称和传入commit编号在命令行参数的角度上二者是互斥的。

对于整个工程项目被修改函数的harness生成这一功能，从get_target_function处获得的函数名应该是一个列表





